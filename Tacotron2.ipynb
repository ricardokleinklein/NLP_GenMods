{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)\n",
    "\n",
    "Find this notebook in https://colab.research.google\n",
    ".com/github/ricardokleinklein/NLP_GenMods/blob/main/Tacotron2.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Modelos Generativos\n",
    "\n",
    "## Tacotron2 - Audio\n",
    "\n",
    "Creado por *Ricardo Kleinlein* para [Saturdays.AI](https://saturdays.ai/).\n",
    "\n",
    "Disponible bajo una licencia [Creative Commons](https://creativecommons.org/licenses/by/4.0/).\n",
    "\n",
    "---"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sobre el uso de Jupyter Notebooks\n",
    "\n",
    "Este notebook ha sido implementado en Python, pero para su ejecución no es\n",
    "necesario conocer el lenguaje en profundidad. Solamente se debe ejecutar cada\n",
    "una de las celdas, teniendo en cuenta que hay que ejecutar una celda a la vez\n",
    "y secuencialmente, tal y como figuran en orden de aparición.\n",
    "\n",
    "Para ejecutar cada celda pulse en el botón ▶ en la esquina superior izquierda\n",
    "de cada celda. Mientras se esté ejecutando ese fragmento de código,\n",
    "el botón estará girando. En caso de querer detener dicha ejecución, pulse\n",
    "nuevamente sobre este botón mientras gira y la ejecución se detendrá. En caso\n",
    "de que la celda tenga alguna salida (texto, gráficos, etc) será mostrada\n",
    "justo después de esta y antes de mostrar la siguiente celda. El notebook\n",
    "estará guiado con todas las explicaciones necesarias, además irá acompañado\n",
    "por comentarios en el código para facilitar su lectura.\n",
    "\n",
    "En caso de tener alguna duda, anótela. Dedicaremos un tiempo a plantear y\n",
    "resolver la mayoría delas dudas que puedan aparecer.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Objetivo del notebook\n",
    "\n",
    "Implementar, descargar y utilizar un modelo de Estado del Arte (Tacotron2)\n",
    "de Text-To-Speech Synthesis (TTS)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sobre el modelo\n",
    "\n",
    "A la hora de generar una voz sintética, existen una serie de factores que se\n",
    " engloban dentro de lo que denominamos \"prosodia\", que constituyen algunos\n",
    " factores especialmente peliagudos de modelar por sistemas automáticos: el\n",
    " ritmo, el énfasis o la entonación. Entre otros atributos físicos, son estos\n",
    "  factores los que hacen una voz más reconocible que otra en muchos casos.\n",
    "\n",
    "Hemos visto en las diapositivas un poco sobre el modelo Wavenet de\n",
    "generación de habla natural. En ese caso, el modelo era un modelo\n",
    "autorregresivo, esto es, que empleaba predicciones anteriores para elaborar\n",
    "futuros puntos de la muestra.\n",
    "\n",
    "El modelo Tacotron original [[paper](https://arxiv.org/abs/1703.10135)] empleaba como componente fundamental\n",
    " Wavenet a la hora de construir habla. Sin embargo, dicho modelo es muy\n",
    " lento a la hora de generar, puesto que tiene que ver muy atrás en el tiempo\n",
    "  para generar cada punto de la muestra.\n",
    "\n",
    "Por ello, Tacotron2 [[paper](https://arxiv.org/abs/1712.05884)] construye sobre esta idea, y propone una\n",
    "solución de compromiso donde sacrifica parte de la \"personalidad\" de la voz\n",
    "por eficiencia en la generación. Si bien Wavenet entraba dentro de la\n",
    "familia de modelos autorregresivos, Tacotron2 se enmarca dentro de las\n",
    "estrategias \"flow-density\".\n",
    "\n",
    "En la imagen inferior se muestra un diagrama de las partes que componen este\n",
    " sistema de síntesis de voz natural.\n",
    "\n",
    "![tacotron2-diagram](./assets/tacotron2_diagram.png)\n",
    "\n",
    "El modelo complementario WaveGlow es un modelo que ha aprendido a generar\n",
    "espectrogramas a partir de texto. Mediante la combinación de Tacotron2 con\n",
    "WaveGlow, el texto nuevo que escribamos como input podrá ser interpretado\n",
    "como habla natural, y se generará en formato de audio.\n",
    "\n",
    "Se podrían modificar aspectos de la voz resultante incorporando información\n",
    "adicional a diferentes niveles dentro del modelo, pero en este ejercicio nos\n",
    " vamos a centrar en cargar el modelo y generar nuestros propios audios.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Instalar las librerías necesarias"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /home/ricardokleinlein/Desktop/satudays/PYTHON/lib/python3.7/site-packages (1.20.3)\n",
      "Requirement already satisfied: scipy in /home/ricardokleinlein/Desktop/satudays/PYTHON/lib/python3.7/site-packages (1.7.1)\n",
      "Collecting librosa\n",
      "  Downloading librosa-0.8.1-py3-none-any.whl (203 kB)\n",
      "Collecting unidecode\n",
      "  Downloading Unidecode-1.3.2-py3-none-any.whl (235 kB)\n",
      "Collecting inflect\n",
      "  Downloading inflect-5.3.0-py3-none-any.whl (32 kB)\n",
      "Requirement already satisfied: joblib>=0.14 in /home/ricardokleinlein/Desktop/satudays/PYTHON/lib/python3.7/site-packages (from librosa) (1.1.0)\n",
      "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /home/ricardokleinlein/Desktop/satudays/PYTHON/lib/python3.7/site-packages (from librosa) (1.0)\n",
      "Requirement already satisfied: decorator>=3.0.0 in /home/ricardokleinlein/Desktop/satudays/PYTHON/lib/python3.7/site-packages (from librosa) (5.1.0)\n",
      "Collecting pooch>=1.0\n",
      "  Downloading pooch-1.5.2-py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied: numba>=0.43.0 in /home/ricardokleinlein/Desktop/satudays/PYTHON/lib/python3.7/site-packages (from librosa) (0.54.1)\n",
      "Collecting resampy>=0.2.2\n",
      "  Using cached resampy-0.2.2.tar.gz (323 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting audioread>=2.0.0\n",
      "  Using cached audioread-2.1.9.tar.gz (377 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting soundfile>=0.10.2\n",
      "  Using cached SoundFile-0.10.3.post1-py2.py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ricardokleinlein/Desktop/satudays/PYTHON/lib/python3.7/site-packages (from librosa) (21.0)\n",
      "Requirement already satisfied: llvmlite<0.38,>=0.37.0rc1 in /home/ricardokleinlein/Desktop/satudays/PYTHON/lib/python3.7/site-packages (from numba>=0.43.0->librosa) (0.37.0)\n",
      "Requirement already satisfied: setuptools in /home/ricardokleinlein/Desktop/satudays/PYTHON/lib/python3.7/site-packages (from numba>=0.43.0->librosa) (39.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/ricardokleinlein/Desktop/satudays/PYTHON/lib/python3.7/site-packages (from packaging>=20.0->librosa) (2.4.7)\n",
      "Collecting appdirs\n",
      "  Using cached appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: requests in /home/ricardokleinlein/Desktop/satudays/PYTHON/lib/python3.7/site-packages (from pooch>=1.0->librosa) (2.26.0)\n",
      "Requirement already satisfied: six>=1.3 in /home/ricardokleinlein/Desktop/satudays/PYTHON/lib/python3.7/site-packages (from resampy>=0.2.2->librosa) (1.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ricardokleinlein/Desktop/satudays/PYTHON/lib/python3.7/site-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa) (3.0.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /home/ricardokleinlein/Desktop/satudays/PYTHON/lib/python3.7/site-packages (from soundfile>=0.10.2->librosa) (1.14.6)\n",
      "Requirement already satisfied: pycparser in /home/ricardokleinlein/Desktop/satudays/PYTHON/lib/python3.7/site-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.20)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ricardokleinlein/Desktop/satudays/PYTHON/lib/python3.7/site-packages (from requests->pooch>=1.0->librosa) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ricardokleinlein/Desktop/satudays/PYTHON/lib/python3.7/site-packages (from requests->pooch>=1.0->librosa) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ricardokleinlein/Desktop/satudays/PYTHON/lib/python3.7/site-packages (from requests->pooch>=1.0->librosa) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ricardokleinlein/Desktop/satudays/PYTHON/lib/python3.7/site-packages (from requests->pooch>=1.0->librosa) (3.3)\n",
      "Building wheels for collected packages: audioread, resampy\n",
      "  Building wheel for audioread (setup.py): started\n",
      "  Building wheel for audioread (setup.py): finished with status 'done'\n",
      "  Created wheel for audioread: filename=audioread-2.1.9-py3-none-any.whl size=23143 sha256=9bda96d05c6d523caf68b2605285ecfeadbce02dd6a7021601a25287669d7171\n",
      "  Stored in directory: /home/ricardokleinlein/.cache/pip/wheels/ba/7b/eb/213741ccc0678f63e346ab8dff10495995ca3f426af87b8d88\n",
      "  Building wheel for resampy (setup.py): started\n",
      "  Building wheel for resampy (setup.py): finished with status 'done'\n",
      "  Created wheel for resampy: filename=resampy-0.2.2-py3-none-any.whl size=320719 sha256=d64093fa0a5cbd07fab58b30dffcf60aa08c1cd83bdcbf7156e5e0f9ba5af1d9\n",
      "  Stored in directory: /home/ricardokleinlein/.cache/pip/wheels/a0/18/0a/8ad18a597d8333a142c9789338a96a6208f1198d290ece356c\n",
      "Successfully built audioread resampy\n",
      "Installing collected packages: appdirs, soundfile, resampy, pooch, audioread, unidecode, librosa, inflect\n",
      "Successfully installed appdirs-1.4.4 audioread-2.1.9 inflect-5.3.0 librosa-0.8.1 pooch-1.5.2 resampy-0.2.2 soundfile-0.10.3.post1 unidecode-1.3.2\n",
      "Reading package lists...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E: Could not open lock file /var/lib/apt/lists/lock - open (13: Permission denied)\n",
      "E: Unable to lock directory /var/lib/apt/lists/\n",
      "W: Problem unlinking the file /var/cache/apt/pkgcache.bin - RemoveCaches (13: Permission denied)\n",
      "W: Problem unlinking the file /var/cache/apt/srcpkgcache.bin - RemoveCaches (13: Permission denied)\n",
      "E: Could not open lock file /var/lib/dpkg/lock-frontend - open (13: Permission denied)\n",
      "E: Unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b'pip install numpy scipy librosa unidecode inflect librosa\\napt-get update\\napt-get install -y libsndfile1\\n\\n'' returned non-zero exit status 100.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mCalledProcessError\u001B[0m                        Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_12054/3004371193.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mget_ipython\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrun_cell_magic\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'bash'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m''\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'pip install numpy scipy librosa unidecode inflect librosa\\napt-get update\\napt-get install -y libsndfile1\\n\\n'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/Desktop/satudays/PYTHON/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001B[0m in \u001B[0;36mrun_cell_magic\u001B[0;34m(self, magic_name, line, cell)\u001B[0m\n\u001B[1;32m   2404\u001B[0m             \u001B[0;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbuiltin_trap\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2405\u001B[0m                 \u001B[0margs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mmagic_arg_s\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcell\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2406\u001B[0;31m                 \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2407\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mresult\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2408\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Desktop/satudays/PYTHON/lib/python3.7/site-packages/IPython/core/magics/script.py\u001B[0m in \u001B[0;36mnamed_script_magic\u001B[0;34m(line, cell)\u001B[0m\n\u001B[1;32m    140\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    141\u001B[0m                 \u001B[0mline\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mscript\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 142\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshebang\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mline\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcell\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    143\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    144\u001B[0m         \u001B[0;31m# write a basic docstring:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Desktop/satudays/PYTHON/lib/python3.7/site-packages/decorator.py\u001B[0m in \u001B[0;36mfun\u001B[0;34m(*args, **kw)\u001B[0m\n\u001B[1;32m    230\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mkwsyntax\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    231\u001B[0m                 \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkw\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfix\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkw\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msig\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 232\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mcaller\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfunc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mextras\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkw\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    233\u001B[0m     \u001B[0mfun\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__name__\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__name__\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    234\u001B[0m     \u001B[0mfun\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__doc__\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__doc__\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Desktop/satudays/PYTHON/lib/python3.7/site-packages/IPython/core/magic.py\u001B[0m in \u001B[0;36m<lambda>\u001B[0;34m(f, *a, **k)\u001B[0m\n\u001B[1;32m    185\u001B[0m     \u001B[0;31m# but it's overkill for just that one bit of state.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    186\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mmagic_deco\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0marg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 187\u001B[0;31m         \u001B[0mcall\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mlambda\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mk\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mk\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    188\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    189\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mcallable\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0marg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Desktop/satudays/PYTHON/lib/python3.7/site-packages/IPython/core/magics/script.py\u001B[0m in \u001B[0;36mshebang\u001B[0;34m(self, line, cell)\u001B[0m\n\u001B[1;32m    243\u001B[0m             \u001B[0msys\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstderr\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mflush\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    244\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mraise_error\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreturncode\u001B[0m\u001B[0;34m!=\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 245\u001B[0;31m             \u001B[0;32mraise\u001B[0m \u001B[0mCalledProcessError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreturncode\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcell\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moutput\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mout\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstderr\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0merr\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    246\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    247\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_run_script\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mp\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcell\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mto_close\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mCalledProcessError\u001B[0m: Command 'b'pip install numpy scipy librosa unidecode inflect librosa\\napt-get update\\napt-get install -y libsndfile1\\n\\n'' returned non-zero exit status 100."
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip install numpy scipy librosa unidecode inflect librosa\n",
    "apt-get update\n",
    "apt-get install -y libsndfile1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Importar los modelos pre-entrenados\n",
    "\n",
    "Estos modelos ocupan mucho espacio en memoria, pero sus tiempos de\n",
    "entrenamiento son aún peores, y requieren de una infraestructura avanzada\n",
    "para poder entrenarlos en plazos de tiempo razonables. Desde luego, exceden\n",
    "en mucho las capacidades de la mayoría de nuestros ordenadores, o del\n",
    "servidor default que Colab nos proporciona.\n",
    "\n",
    "Afortunadamente, NVIDIA proporciona un servidor desde el que descargar un\n",
    "modelo completamente preentrenado.\n",
    "\n",
    "### Tacotron2\n",
    "\n",
    "Esta versión de Tacotron2 es casi idéntica en arquitectura al original como\n",
    "aparece publicado en el paper, con modificaciones mínimas en algunas capas.\n",
    "Ha sido entrenado en la base de datos [LJSpeech](https://keithito.com/LJ-Speech-Dataset/), la cual constituye una\n",
    "de las referencias principales a la hora de entrenar modelos de síntesis de\n",
    "voz. Probablemente la otra mayor base de datos a tal efecto sea [VCTK](https://datashare.ed.ac.uk/handle/10283/2950),\n",
    "desarrollada por Junichi Yamagishi en Edimburgo, con quién trabajé en Tokyo.\n",
    "\n",
    "LJSpeech consta de ..."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/NVIDIA/DeepLearningExamples/archive/torchhub.zip\" to /home/ricardokleinlein/.cache/torch/hub/torchhub.zip\n",
      "Downloading checkpoint from https://api.ngc.nvidia.com/v2/models/nvidia/tacotron2_pyt_ckpt_amp/versions/19.09.0/files/nvidia_tacotron2pyt_fp16_20190427\n"
     ]
    },
    {
     "data": {
      "text/plain": "Tacotron2(\n  (embedding): Embedding(148, 512)\n  (encoder): Encoder(\n    (convolutions): ModuleList(\n      (0): Sequential(\n        (0): ConvNorm(\n          (conv): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n        )\n        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): Sequential(\n        (0): ConvNorm(\n          (conv): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n        )\n        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (2): Sequential(\n        (0): ConvNorm(\n          (conv): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n        )\n        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (lstm): LSTM(512, 256, batch_first=True, bidirectional=True)\n  )\n  (decoder): Decoder(\n    (prenet): Prenet(\n      (layers): ModuleList(\n        (0): LinearNorm(\n          (linear_layer): Linear(in_features=80, out_features=256, bias=False)\n        )\n        (1): LinearNorm(\n          (linear_layer): Linear(in_features=256, out_features=256, bias=False)\n        )\n      )\n    )\n    (attention_rnn): LSTMCell(768, 1024)\n    (attention_layer): Attention(\n      (query_layer): LinearNorm(\n        (linear_layer): Linear(in_features=1024, out_features=128, bias=False)\n      )\n      (memory_layer): LinearNorm(\n        (linear_layer): Linear(in_features=512, out_features=128, bias=False)\n      )\n      (v): LinearNorm(\n        (linear_layer): Linear(in_features=128, out_features=1, bias=False)\n      )\n      (location_layer): LocationLayer(\n        (location_conv): ConvNorm(\n          (conv): Conv1d(2, 32, kernel_size=(31,), stride=(1,), padding=(15,), bias=False)\n        )\n        (location_dense): LinearNorm(\n          (linear_layer): Linear(in_features=32, out_features=128, bias=False)\n        )\n      )\n    )\n    (decoder_rnn): LSTMCell(1536, 1024, bias=1)\n    (linear_projection): LinearNorm(\n      (linear_layer): Linear(in_features=1536, out_features=80, bias=True)\n    )\n    (gate_layer): LinearNorm(\n      (linear_layer): Linear(in_features=1536, out_features=1, bias=True)\n    )\n  )\n  (postnet): Postnet(\n    (convolutions): ModuleList(\n      (0): Sequential(\n        (0): ConvNorm(\n          (conv): Conv1d(80, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n        )\n        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): Sequential(\n        (0): ConvNorm(\n          (conv): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n        )\n        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (2): Sequential(\n        (0): ConvNorm(\n          (conv): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n        )\n        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (3): Sequential(\n        (0): ConvNorm(\n          (conv): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n        )\n        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (4): Sequential(\n        (0): ConvNorm(\n          (conv): Conv1d(512, 80, kernel_size=(5,), stride=(1,), padding=(2,))\n        )\n        (1): BatchNorm1d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n  )\n)"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Tuple\n",
    "from IPython.display import Audio\n",
    "import torch\n",
    "\n",
    "TacotronModel = Tuple[torch.nn.Module, torch.nn.Module]\n",
    "\n",
    "tacotron2 = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub',\n",
    "                           'nvidia_tacotron2', model_math='fp16')\n",
    "tacotron2 = tacotron2.to('cuda')\n",
    "tacotron2.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Podemos repasar las líneas desplegadas para comprobar, junto con el diagrama\n",
    " mostrado al inicio, que la arquitectura es correcta.\n",
    "\n",
    "### WaveGlow\n",
    "\n",
    "En nuestro ejemplo, WaveGlow juega el rol de un *vocoder*, una herramienta\n",
    "que convierte una codificación numérica del habla en sonidos audibles."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "waveglow = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_waveglow', model_math='fp16')\n",
    "waveglow = waveglow.remove_weightnorm(waveglow)\n",
    "waveglow = waveglow.to('cuda')\n",
    "waveglow.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "En este momento ya estamos preparados para sintetizar audio. Por comodidad,\n",
    "vamos a agrupar una serie de operaciones dedicadas a preprocesar el input\n",
    "con que alimentaremos al modelo:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "utils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub',\n",
    "                       'nvidia_tts_utils')\n",
    "\n",
    "def synthesize(text: str, model: TacotronModel):\n",
    "    \"\"\"Adjust input text length by padding, and feed to model.\n",
    "\n",
    "    :param text: Uttered speech.\n",
    "    :param model: Tuple with instances of (Tacotron, WaveGlow).\n",
    "    :return:\n",
    "        numpy.ndarray with utterance.\n",
    "    \"\"\"\n",
    "    sequences, lengths = utils.prepare_input_sequence([text])\n",
    "    with torch.no_grad():\n",
    "        mel, _, _ = model[0].infer(sequences, lengths)\n",
    "        audio = model[1].infer(mel)\n",
    "    return audio[0].data.cpu().numpy()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Playground\n",
    "\n",
    "Ahora solo resta escribir una cadena de texto (en inglés para obtener\n",
    "mejores resultados) y escuchar cuál es el resultado."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "text = \"Isn't Machine Learning something absolutely fabulous?\"\n",
    "signal = synthesize(text, (tacotron2, waveglow))\n",
    "Audio(signal, rate=22050)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}