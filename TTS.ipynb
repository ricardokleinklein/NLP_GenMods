{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)\n",
    "(https://colab.research.google.com/github/ricardokleinklein/NLP_GenMods/blob/main/TTS.ipynb)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Modelos Generativos\n",
    "\n",
    "## WaveNet - Audio\n",
    "\n",
    "Creado por *Ricardo Kleinlein* para [Saturdays.AI](https://saturdays.ai/).\n",
    "\n",
    "Disponible bajo una licencia [Creative Commons](https://creativecommons.org/licenses/by/4.0/).\n",
    "\n",
    "---"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sobre el uso de Jupyter Notebooks\n",
    "\n",
    "Este notebook ha sido implementado en Python, pero para su ejecución no es\n",
    "necesario conocer el lenguaje en profundidad. Solamente se debe ejecutar cada\n",
    "una de las celdas, teniendo en cuenta que hay que ejecutar una celda a la vez\n",
    "y secuencialmente, tal y como figuran en orden de aparición.\n",
    "\n",
    "Para ejecutar cada celda pulse en el botón ▶ en la esquina superior izquierda\n",
    "de cada celda. Mientras se esté ejecutando ese fragmento de código,\n",
    "el botón estará girando. En caso de querer detener dicha ejecución, pulse\n",
    "nuevamente sobre este botón mientras gira y la ejecución se detendrá. En caso\n",
    "de que la celda tenga alguna salida (texto, gráficos, etc) será mostrada\n",
    "justo después de esta y antes de mostrar la siguiente celda. El notebook\n",
    "estará guiado con todas las explicaciones necesarias, además irá acompañado\n",
    "por comentarios en el código para facilitar su lectura.\n",
    "\n",
    "En caso de tener alguna duda, anótela. Dedicaremos un tiempo a plantear y\n",
    "resolver la mayoría delas dudas que puedan aparecer.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Objetivo del notebook\n",
    "\n",
    "Tener una intuición acerca de cómo podemos generar habla sintética a partir\n",
    "de mensajes en texto mediante la red neuronal profunda WaveNet.\n",
    "\n",
    "### Disclaimer\n",
    "\n",
    "Trabajar con el modelo completo requeriría GPUs, toneladas de cálculos y\n",
    "mucho tiempo. El WaveNet original tarda hasta 5 minutos en generar cada\n",
    "segundo de audio, por lo que aquí vamos a trabajar mediante la API de Google\n",
    " Translate.\n",
    "\n",
    "## Sobre el modelo\n",
    "\n",
    "Vamos a emplear la versión de WaveNet que utiliza Google Translate por\n",
    "defecto para dar voz a las traducciones generadas. En el modelo original,\n",
    "mostrado abajo, existen muchas maneras de modificar la voz producida, la\n",
    "cual ni siquiera debe circunscribirse a un texto en concreto (véase [el blog\n",
    "original](https://deepmind.com/blog/article/wavenet-generative-model-raw\n",
    "-audio) y las muestras de audio que adjuntan).\n",
    "\n",
    "![Estructura generativa Wavenet](./assets/wavenet.gif)\n",
    "\n",
    "Procedimientos habituales son \"condicionar\" la señal de entrada para generar\n",
    " voces con acentos concretos, cambiar el sexo de la voz, o la que\n",
    " realizaremos nosotros, escribir explícitamente qué queremos que diga."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Importar las librerías necesarias"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "!pip install gTTS\n",
    "from gtts import gTTS\n",
    "from IPython.display import Audio"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Vamos a ver ejemplos de generación en inglés y en español, pero existe un\n",
    "# gama enorme de idiomas en los que trabajar. Véase:\n",
    "# https://gtts.readthedocs.io/en/latest/module.html#languages-gtts-lang\n",
    "\n",
    "spa_example = gTTS('Saludos de parte de todo el equipo de Saturdays.AI',\n",
    "                   lang=\"es\")\n",
    "spa_example.save('/content/SPA-example.mp3')\n",
    "Audio('/content/SPA-example.mp3', autoplay=True)\n",
    "\n",
    "eng_example = gTTS('Greetings on behalf of the team of Saturdays.AI',\n",
    "                   lang='en')\n",
    "eng_example.save('/content/ENG-example.mp3')\n",
    "Audio('/content/ENG-example.mp3', autoplay=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## DeepVoice3\n",
    "\n",
    "DeepVoice es un modelo de Text-To-Speech Synthesis centrado únicamente en la\n",
    " combinación de capas convolucionales y atención."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import exists, join, expanduser\n",
    "\n",
    "# Clone\n",
    "name = \"deepvoice3_pytorch\"\n",
    "if not exists(name):\n",
    "  ! git clone https://github.com/r9y9/$name\n",
    "# Change working directory to the project dir\n",
    "os.chdir(join(expanduser(\"~\"), name))\n",
    "!git checkout 7a10ac6763eda92595e257543494b6a95f64229b --quiet\n",
    "# Install dependencices\n",
    "!pip install -q -e '.[bin]'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "! pip install -q librosa nltk\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython\n",
    "from IPython.display import Audio\n",
    "# need this for English text processing frontend\n",
    "import nltk\n",
    "! python -m nltk.downloader cmudict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Descargamos el modelo pre-entrenado"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "preset = \"20180505_deepvoice3_ljspeech.json\"\n",
    "checkpoint_path = \"20180505_deepvoice3_checkpoint_step000640000.pth\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if not exists(preset):\n",
    "  !curl -O -L \"https://www.dropbox.com/s/0ck82unm0bo0rxd/20180505_deepvoice3_ljspeech.json\"\n",
    "if not exists(checkpoint_path):\n",
    "  !curl -O -L \"https://www.dropbox.com/s/5ucl9remrwy5oeg/20180505_deepvoice3_checkpoint_step000640000.pth\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sintetizamos con este nuevo modelo\n",
    "\n",
    "Primero definimos los hiperparámetros del modelo"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import hparams\n",
    "import json\n",
    "\n",
    "# Load parameters from preset\n",
    "with open(preset) as f:\n",
    "  hparams.hparams.parse_json(f.read())\n",
    "\n",
    "# Inject frontend text processor\n",
    "import synthesis\n",
    "import train\n",
    "from deepvoice3_pytorch import frontend\n",
    "synthesis._frontend = getattr(frontend, \"en\")\n",
    "train._frontend =  getattr(frontend, \"en\")\n",
    "\n",
    "# alises\n",
    "fs = hparams.hparams.sample_rate\n",
    "hop_length = hparams.hparams.hop_size"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Definimos algunas funciones prácticas"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def tts(model, text, p=0, speaker_id=None, fast=True, figures=True):\n",
    "  from synthesis import tts as _tts\n",
    "  waveform, alignment, spectrogram, mel = _tts(model, text, p, speaker_id, fast)\n",
    "  if figures:\n",
    "      visualize(alignment, spectrogram)\n",
    "  IPython.display.display(Audio(waveform, rate=fs))\n",
    "\n",
    "def visualize(alignment, spectrogram):\n",
    "  label_fontsize = 16\n",
    "  figure(figsize=(16,16))\n",
    "\n",
    "  subplot(2,1,1)\n",
    "  imshow(alignment.T, aspect=\"auto\", origin=\"lower\", interpolation=None)\n",
    "  xlabel(\"Decoder timestamp\", fontsize=label_fontsize)\n",
    "  ylabel(\"Encoder timestamp\", fontsize=label_fontsize)\n",
    "  colorbar()\n",
    "\n",
    "  subplot(2,1,2)\n",
    "  librosa.display.specshow(spectrogram.T, sr=fs,\n",
    "                           hop_length=hop_length, x_axis=\"time\", y_axis=\"linear\")\n",
    "  xlabel(\"Time\", fontsize=label_fontsize)\n",
    "  ylabel(\"Hz\", fontsize=label_fontsize)\n",
    "  tight_layout()\n",
    "  colorbar()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Cargamos el modelo"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from train import build_model\n",
    "from train import restore_parts, load_checkpoint\n",
    "\n",
    "model = build_model()\n",
    "model = load_checkpoint(checkpoint_path, model, None, True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Vamos a generar audio a partir de frases"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"Scientists at the CERN laboratory say they have discovered a new particle.\",\n",
    "    \"There's a way to measure the acute emotional intelligence that has never gone out of style.\",\n",
    "    \"President Trump met with other leaders at the Group of 20 conference.\",\n",
    "    \"The Senate's bill to repeal and replace the Affordable Care Act is now imperiled.\",\n",
    "    \"Generative adversarial network or variational auto-encoder.\",\n",
    "    \"The buses aren't the problem, they actually provide a solution.\",\n",
    "    \"peter piper picked a peck of pickled peppers how many peppers did peter piper pick.\",\n",
    "    \"Some have accepted this as a miracle without any physical explanation.\",\n",
    "]\n",
    "\n",
    "for idx, text in enumerate(texts):\n",
    "  print(idx, text)\n",
    "  tts(model, text, figures=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}